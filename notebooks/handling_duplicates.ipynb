{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60cd23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries and define helper functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder, PowerTransformer\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22f13cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define the transform_skewed_features and check_skewness functions\n",
    "def transform_skewed_features(data, transformation_map):\n",
    "    \"\"\"\n",
    "    Apply the best transformation to each feature based on the provided mapping\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame\n",
    "        The dataframe containing the skewed columns\n",
    "    transformation_map : dict\n",
    "        Dictionary mapping column names to their best transformation method\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    transformed_data : pandas DataFrame\n",
    "        A copy of the original dataframe with transformed columns\n",
    "    \"\"\"\n",
    "    transformed_data = data.copy()\n",
    "    \n",
    "    for column, transform_method in transformation_map.items():\n",
    "        if column in data.columns:\n",
    "            series = data[column].dropna()\n",
    "            \n",
    "            if transform_method == 'Yeo–Johnson':\n",
    "                pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "                transformed_values = pt.fit_transform(series.values.reshape(-1, 1)).flatten()\n",
    "                transformed_data.loc[series.index, column] = transformed_values\n",
    "                \n",
    "            elif transform_method == 'Log1p':\n",
    "                transformed_data.loc[series.index, column] = np.log1p(series)\n",
    "                \n",
    "            elif transform_method == 'Combined':\n",
    "                # Apply Yeo-Johnson first, then log1p\n",
    "                pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "                yj_transformed = pt.fit_transform(series.values.reshape(-1, 1)).flatten()\n",
    "                transformed_data.loc[series.index, column] = np.log1p(yj_transformed)\n",
    "                \n",
    "            elif transform_method == 'Box-Cox + log1p':\n",
    "                # Apply Box-Cox first, then log1p\n",
    "                # Note: Box-Cox requires all values to be positive\n",
    "                min_val = series.min()\n",
    "                if min_val <= 0:\n",
    "                    # Shift data to make all values positive\n",
    "                    shifted_series = series - min_val + 1\n",
    "                else:\n",
    "                    shifted_series = series\n",
    "                    \n",
    "                pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "                bc_transformed = pt.fit_transform(shifted_series.values.reshape(-1, 1)).flatten()\n",
    "                transformed_data.loc[series.index, column] = np.log1p(bc_transformed)\n",
    "                \n",
    "            # If method is 'Original', keep the original values\n",
    "    \n",
    "    return transformed_data\n",
    "\n",
    "\n",
    "def check_skewness(original_data, transformed_data, columns):\n",
    "    results = []\n",
    "    for col in columns:\n",
    "        if col in original_data.columns and col in transformed_data.columns:\n",
    "            original_skew = original_data[col].skew()\n",
    "            transformed_skew = transformed_data[col].skew()\n",
    "            results.append({\n",
    "                'Feature': col,\n",
    "                'Original skew': original_skew,\n",
    "                'Transformed skew': transformed_skew,\n",
    "                'Improvement': abs(original_skew) - abs(transformed_skew)\n",
    "            })\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48974ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load dataset and define constants\n",
    "# Load dataset\n",
    "dataset_path = \"Data/phase2_students_before_cleaning.csv\"  # adjust as needed\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Base directory for saving\n",
    "base_dir = Path(dataset_path).parent\n",
    "\n",
    "# Define target column\n",
    "target_column = 'label'  # change to your actual target\n",
    "\n",
    "# Columns to base deduplication on (only numerical features)\n",
    "numeric_cols = [\n",
    "    'flow_time', 'header_size', 'packet_duration', 'overall_rate', 'src_rate', 'dst_rate', \n",
    "    'fin_packets', 'urg_packets', 'rst_packets', 'max_value', 'value_covariance'\n",
    "]\n",
    "\n",
    "# Define the best transformation for each column\n",
    "best_transforms = {\n",
    "    'flow_time': 'Combined',\n",
    "    'header_size': 'Yeo–Johnson',\n",
    "    'packet_duration': 'Log1p',\n",
    "    'overall_rate': 'Yeo–Johnson',\n",
    "    'src_rate': 'Yeo–Johnson',\n",
    "    'dst_rate': 'Yeo–Johnson',\n",
    "    'fin_packets': 'Combined',\n",
    "    'urg_packets': 'Combined',\n",
    "    'rst_packets': 'Combined',\n",
    "    'max_value': 'Box-Cox + log1p',\n",
    "    'value_covariance': 'Combined'\n",
    "}\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8da75fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Direct_Removal...\n",
      "\n",
      "Skewness improvement for Direct_Removal:\n",
      "             Feature  Original skew  Transformed skew  Improvement\n",
      "0          flow_time     813.536437          1.336008   812.200429\n",
      "1        header_size      83.332541          0.052562    83.279979\n",
      "2    packet_duration      10.362799          7.842132     2.520666\n",
      "3       overall_rate      35.407439          0.271302    35.136137\n",
      "4           src_rate      35.407439          0.271302    35.136137\n",
      "5           dst_rate     313.605366          0.000000   313.605366\n",
      "6        fin_packets       3.916024          2.509267     1.406758\n",
      "7        urg_packets      23.758800          2.093620    21.665179\n",
      "8        rst_packets      12.467244          1.836099    10.631145\n",
      "9          max_value       9.719423          0.962519     8.756904\n",
      "10  value_covariance     102.462206          1.035220   101.426986\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Method 1 - Direct Removal\n",
    "def direct_removal(X, y):\n",
    "    combined = pd.concat([X, y], axis=1)\n",
    "    dedup = combined.drop_duplicates(subset=numeric_cols + [target_column])\n",
    "    return dedup.drop(columns=[target_column]), dedup[target_column]\n",
    "\n",
    "# Execute Method 1\n",
    "print(\"Processing Direct_Removal...\")\n",
    "X_dedup, y_dedup = direct_removal(X, y)\n",
    "y_encoded = pd.Series(label_encoder.fit_transform(y_dedup), name=target_column)\n",
    "\n",
    "# split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_dedup,\n",
    "    y_encoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded           # preserves class ratios\n",
    ")\n",
    "\n",
    "# Apply transformation only to training data\n",
    "X_train_transformed = transform_skewed_features(\n",
    "    X_train,\n",
    "    {k: v for k, v in best_transforms.items() if k in X_train.columns}\n",
    ")\n",
    "\n",
    "# Print skewness improvement for training data\n",
    "skew_comparison = check_skewness(\n",
    "    X_train,\n",
    "    X_train_transformed,\n",
    "    [col for col in best_transforms.keys() if col in X_train.columns]\n",
    ")\n",
    "print(\"\\nSkewness improvement for Direct_Removal:\")\n",
    "print(skew_comparison)\n",
    "\n",
    "# Save transformed training data\n",
    "X_train_transformed.to_csv(base_dir / \"phase2_Direct_Removal_X_train.csv\", index=False)\n",
    "X_test.to_csv(base_dir / \"phase2_Direct_Removal_X_test.csv\", index=False)\n",
    "y_train.to_csv(base_dir / \"phase2_Direct_Removal_y_train.csv\", index=False)\n",
    "y_test.to_csv(base_dir / \"phase2_Direct_Removal_y_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91a764dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Instance_Weighting...\n",
      "\n",
      "Skewness improvement for Instance_Weighting:\n",
      "             Feature  Original skew  Transformed skew  Improvement\n",
      "0          flow_time     190.836679          1.460719   189.375960\n",
      "1        header_size      90.252863          0.053950    90.198913\n",
      "2    packet_duration      10.864631          8.302737     2.561894\n",
      "3       overall_rate      22.719804          0.263820    22.455984\n",
      "4           src_rate      22.719804          0.263820    22.455984\n",
      "5           dst_rate     809.550333          0.000000   809.550333\n",
      "6        fin_packets       3.515336          2.404278     1.111058\n",
      "7        urg_packets      25.101142          2.106201    22.994941\n",
      "8        rst_packets      13.193635          1.858091    11.335545\n",
      "9          max_value      10.173905          0.918126     9.255780\n",
      "10  value_covariance     110.565900          1.181848   109.384052\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Method 4 - Instance Weighting\n",
    "def instance_weighting(X, y):\n",
    "    combined = pd.concat([X, y], axis=1)\n",
    "    weights = combined.groupby(numeric_cols + [target_column]) \\\n",
    "                      .size().reset_index(name='weight')\n",
    "    weighted_df = combined.merge(\n",
    "        weights,\n",
    "        left_on=numeric_cols + [target_column],\n",
    "        right_on=numeric_cols + [target_column]\n",
    "    )\n",
    "    X_w = weighted_df.drop(columns=[target_column, 'weight'])\n",
    "    y_w = weighted_df[target_column]\n",
    "    sample_weights = weighted_df['weight']\n",
    "    return X_w, y_w, sample_weights\n",
    "\n",
    "# Execute Method 4\n",
    "print(\"Processing Instance_Weighting...\")\n",
    "X_w, y_w, w = instance_weighting(X, y)\n",
    "y_encoded = pd.Series(label_encoder.fit_transform(y_w), name=target_column)\n",
    "\n",
    "# split with stratification\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X_w,\n",
    "    y_encoded,\n",
    "    w,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded           # preserves class ratios here too\n",
    ")\n",
    "\n",
    "# Apply transformation only to training data\n",
    "X_train_transformed = transform_skewed_features(\n",
    "    X_train,\n",
    "    {k: v for k, v in best_transforms.items() if k in X_train.columns}\n",
    ")\n",
    "\n",
    "# Print skewness improvement for training data\n",
    "skew_comparison = check_skewness(\n",
    "    X_train,\n",
    "    X_train_transformed,\n",
    "    [col for col in best_transforms.keys() if col in X_train.columns]\n",
    ")\n",
    "print(\"\\nSkewness improvement for Instance_Weighting:\")\n",
    "print(skew_comparison)\n",
    "\n",
    "# Save transformed training data and weights\n",
    "X_train_transformed.to_csv(base_dir / \"phase2_Instance_Weighting_X_train.csv\", index=False)\n",
    "X_test.to_csv(base_dir / \"phase2_Instance_Weighting_X_test.csv\", index=False)\n",
    "y_train.to_csv(base_dir / \"phase2_Instance_Weighting_y_train.csv\", index=False)\n",
    "y_test.to_csv(base_dir / \"phase2_Instance_Weighting_y_test.csv\", index=False)\n",
    "pd.DataFrame({'weight': w_train}).to_csv(\n",
    "    base_dir / \"phase2_Instance_Weighting_weights_train.csv\", index=False\n",
    ")\n",
    "pd.DataFrame({'weight': w_test}).to_csv(\n",
    "    base_dir / \"phase2_Instance_Weighting_weights_test.csv\", index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81176557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loaded X_train with shape: (737580, 21)\n",
      "Applying skewness transformations...\n",
      "\n",
      "Skewness improvement after transformations:\n",
      "             Feature  Original skew  Transformed skew  Improvement\n",
      "0          flow_time     662.029643          1.440893   660.588751\n",
      "1        header_size      87.959323          0.053391    87.905932\n",
      "2    packet_duration      10.734725          8.226282     2.508443\n",
      "3       overall_rate      31.262338          0.265660    30.996678\n",
      "4           src_rate      31.262338          0.265660    30.996678\n",
      "5           dst_rate     807.523598          0.000000   807.523598\n",
      "6        fin_packets       3.576488          2.420061     1.156427\n",
      "7        urg_packets      24.593968          2.098304    22.495664\n",
      "8        rst_packets      13.012618          1.851864    11.160754\n",
      "9          max_value      10.140544          0.924946     9.215598\n",
      "10  value_covariance     107.381428          1.157036   106.224391\n",
      "\n",
      "Saving transformed training data to C:\\Machine Learning\\Phase 2\\Data\\deduplicated_datasets\\Train_Test_Aware\\transformed...\n",
      "Done! Successfully applied skewness transformations to training data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Define path to training data only\n",
    "base_dir = Path(r\"C:\\Machine Learning\\Phase 2\\Data\\deduplicated_datasets\\Train_Test_Aware\")\n",
    "X_train_path = base_dir / \"phase2_TrainTestAware_X_train.csv\"\n",
    "\n",
    "# Define the transform_skewed_features function\n",
    "def transform_skewed_features(data, transformation_map):\n",
    "    \"\"\"\n",
    "    Apply the best transformation to each feature based on the provided mapping\n",
    "    \"\"\"\n",
    "    transformed_data = data.copy()\n",
    "    \n",
    "    for column, transform_method in transformation_map.items():\n",
    "        if column in data.columns:\n",
    "            series = data[column].dropna()\n",
    "            \n",
    "            if transform_method == 'Yeo–Johnson':\n",
    "                pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "                transformed_values = pt.fit_transform(series.values.reshape(-1, 1)).flatten()\n",
    "                transformed_data.loc[series.index, column] = transformed_values\n",
    "                \n",
    "            elif transform_method == 'Log1p':\n",
    "                transformed_data.loc[series.index, column] = np.log1p(series)\n",
    "                \n",
    "            elif transform_method == 'Combined':\n",
    "                # Apply Yeo-Johnson first, then log1p\n",
    "                pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "                yj_transformed = pt.fit_transform(series.values.reshape(-1, 1)).flatten()\n",
    "                transformed_data.loc[series.index, column] = np.log1p(yj_transformed)\n",
    "                \n",
    "            elif transform_method == 'Box-Cox + log1p':\n",
    "                # Apply Box-Cox first, then log1p\n",
    "                # Note: Box-Cox requires all values to be positive\n",
    "                min_val = series.min()\n",
    "                if min_val <= 0:\n",
    "                    # Shift data to make all values positive\n",
    "                    shifted_series = series - min_val + 1\n",
    "                else:\n",
    "                    shifted_series = series\n",
    "                    \n",
    "                pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "                bc_transformed = pt.fit_transform(shifted_series.values.reshape(-1, 1)).flatten()\n",
    "                transformed_data.loc[series.index, column] = np.log1p(bc_transformed)\n",
    "    \n",
    "    return transformed_data\n",
    "\n",
    "def check_skewness(original_data, transformed_data, columns):\n",
    "    results = []\n",
    "    for col in columns:\n",
    "        if col in original_data.columns and col in transformed_data.columns:\n",
    "            original_skew = original_data[col].skew()\n",
    "            transformed_skew = transformed_data[col].skew()\n",
    "            results.append({\n",
    "                'Feature': col,\n",
    "                'Original skew': original_skew,\n",
    "                'Transformed skew': transformed_skew,\n",
    "                'Improvement': abs(original_skew) - abs(transformed_skew)\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Define the best transformation for each column\n",
    "best_transforms = {\n",
    "    'flow_time': 'Combined',\n",
    "    'header_size': 'Yeo–Johnson',\n",
    "    'packet_duration': 'Log1p',\n",
    "    'overall_rate': 'Yeo–Johnson',\n",
    "    'src_rate': 'Yeo–Johnson',\n",
    "    'dst_rate': 'Yeo–Johnson',\n",
    "    'fin_packets': 'Combined',\n",
    "    'urg_packets': 'Combined',\n",
    "    'rst_packets': 'Combined',\n",
    "    'max_value': 'Box-Cox + log1p',\n",
    "    'value_covariance': 'Combined'\n",
    "}\n",
    "\n",
    "# Load only the training data\n",
    "print(\"Loading training data...\")\n",
    "X_train = pd.read_csv(X_train_path)\n",
    "print(f\"Loaded X_train with shape: {X_train.shape}\")\n",
    "\n",
    "# Apply transformation to training data\n",
    "print(\"Applying skewness transformations...\")\n",
    "X_train_transformed = transform_skewed_features(X_train, \n",
    "                                              {k: v for k, v in best_transforms.items() if k in X_train.columns})\n",
    "\n",
    "# Print skewness improvement for training data\n",
    "skew_comparison = check_skewness(X_train, X_train_transformed, \n",
    "                                [col for col in best_transforms.keys() if col in X_train.columns])\n",
    "print(\"\\nSkewness improvement after transformations:\")\n",
    "print(skew_comparison)\n",
    "\n",
    "# Create output directory for transformed data if it doesn't exist\n",
    "output_dir = base_dir / \"transformed\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save only the transformed training data\n",
    "print(f\"\\nSaving transformed training data to {output_dir}...\")\n",
    "X_train_transformed.to_csv(output_dir / \"phase2_TrainTestAware_X_train_transformed.csv\", index=False)\n",
    "\n",
    "print(\"Done! Successfully applied skewness transformations to training data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
