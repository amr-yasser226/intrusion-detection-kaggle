{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86967d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe99e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data\\\\phase2_students_before_cleaning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f3fa323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          flow_time   header_size  packet_duration  overall_rate  \\\n",
      "count  9.385830e+05  9.385830e+05    938583.000000  9.385830e+05   \n",
      "mean   1.342515e+01  1.018134e+05        82.664589  9.163496e+03   \n",
      "std    5.898099e+03  1.801377e+06       166.986325  1.001806e+05   \n",
      "min    0.000000e+00  0.000000e+00         0.000000  0.000000e+00   \n",
      "25%    0.000000e+00  5.400000e+01        64.000000  2.077046e+00   \n",
      "50%    0.000000e+00  5.400000e+01        64.000000  1.570377e+01   \n",
      "75%    1.017542e-01  3.640000e+02        64.000000  1.177706e+02   \n",
      "max    4.930147e+06  3.311174e+08      6525.740000  7.340032e+06   \n",
      "\n",
      "           src_rate       dst_rate    fin_packets    urg_packets  \\\n",
      "count  9.385830e+05  938583.000000  938583.000000  938583.000000   \n",
      "mean   9.163496e+03       0.000002       0.099474       5.850813   \n",
      "std    1.001806e+05       0.000898       0.299712      70.715367   \n",
      "min    0.000000e+00       0.000000       0.000000       0.000000   \n",
      "25%    2.077046e+00       0.000000       0.000000       0.000000   \n",
      "50%    1.570377e+01       0.000000       0.000000       0.000000   \n",
      "75%    1.177706e+02       0.000000       0.000000       0.000000   \n",
      "max    7.340032e+06       0.848465      19.500000    4136.700000   \n",
      "\n",
      "         rst_packets      max_value  ...      fin_flags      syn_flags  \\\n",
      "count  938583.000000  938583.000000  ...  938583.000000  938583.000000   \n",
      "mean       37.137514     177.161360  ...       0.087102       0.208346   \n",
      "std       324.613580     515.425327  ...       0.281984       0.406126   \n",
      "min         0.000000      42.000000  ...       0.000000       0.000000   \n",
      "25%         0.000000      50.000000  ...       0.000000       0.000000   \n",
      "50%         0.000000      54.000000  ...       0.000000       0.000000   \n",
      "75%         0.010000      55.140000  ...       0.000000       0.000000   \n",
      "max      9331.500000   30329.200000  ...       1.000000       1.000000   \n",
      "\n",
      "           rst_flags      psh_flags      ack_flags  protocol_http  \\\n",
      "count  938583.000000  938583.000000  938583.000000  938583.000000   \n",
      "mean        0.091149       0.088415       0.121502       0.048001   \n",
      "std         0.287821       0.283898       0.326710       0.213769   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "       protocol_https   protocol_tcp   protocol_udp  protocol_icmp  \n",
      "count   938583.000000  938583.000000  938583.000000  938583.000000  \n",
      "mean         0.054196       0.574175       0.211410       0.164314  \n",
      "std          0.226403       0.494468       0.408309       0.370560  \n",
      "min          0.000000       0.000000       0.000000       0.000000  \n",
      "25%          0.000000       0.000000       0.000000       0.000000  \n",
      "50%          0.000000       1.000000       0.000000       0.000000  \n",
      "75%          0.000000       1.000000       0.000000       0.000000  \n",
      "max          1.000000       1.000000       1.000000       1.000000  \n",
      "\n",
      "[8 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ff9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                count    percent\n",
      "label                           \n",
      "DDoS           687027  73.198321\n",
      "DoS            163428  17.412205\n",
      "Mirai           53395   5.688895\n",
      "BenignTraffic   21987   2.342574\n",
      "Recon            6433   0.685395\n",
      "MITM             6313   0.672610\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 2. Get raw counts\n",
    "counts = data[\"label\"].value_counts()\n",
    "\n",
    "# 3. Get relative frequencies\n",
    "freqs = data[\"label\"].value_counts(normalize=True) * 100\n",
    "\n",
    "# 4. Combine into one table\n",
    "imbalance_data = pd.concat(\n",
    "    [counts.rename(\"count\"), freqs.rename(\"percent\")],\n",
    "    axis=1\n",
    ").sort_values(by=\"percent\", ascending=False)\n",
    "\n",
    "print(imbalance_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81b37cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns to transform: ['flow_time', 'header_size', 'packet_duration', 'overall_rate', 'src_rate', 'dst_rate', 'fin_packets', 'urg_packets', 'rst_packets', 'max_value', 'value_covariance']\n",
      "Skewness before transformations:\n",
      "                 flow_time  header_size  packet_duration  overall_rate  \\\n",
      "BenignTraffic   21.553083    22.626066        12.334105     18.514660   \n",
      "DDoS           828.622012   471.864703         9.871309     19.948004   \n",
      "DoS            109.027356    26.496179        10.514410     31.088226   \n",
      "MITM            41.064835    19.889861        15.997384     19.045760   \n",
      "Mirai          120.868408    30.754763        10.545856     17.715730   \n",
      "Recon           79.703750    33.956999        12.913901     27.402579   \n",
      "\n",
      "                src_rate    dst_rate  fin_packets  urg_packets  rst_packets  \\\n",
      "BenignTraffic  18.514660    0.000000   103.556296     6.831121     2.067410   \n",
      "DDoS           19.948004  771.152026     2.473504   163.261103   101.573801   \n",
      "DoS            31.088226    0.000000    11.548110    93.939784    54.174453   \n",
      "MITM           19.045760    0.000000    13.302955     2.101351     1.490997   \n",
      "Mirai          17.715730    0.000000    68.108530    56.277024    54.355045   \n",
      "Recon          27.402579    0.000000     1.102928     4.154858     3.713091   \n",
      "\n",
      "               max_value  value_covariance  \n",
      "BenignTraffic   2.810491         20.059117  \n",
      "DDoS            5.547301         19.968057  \n",
      "DoS            10.714606         19.194583  \n",
      "MITM            1.417151          6.707442  \n",
      "Mirai          18.942672         46.580560  \n",
      "Recon           3.635836         11.493584  \n",
      "\n",
      "Skewness after log1p:\n",
      "                flow_time  header_size  packet_duration  overall_rate  \\\n",
      "BenignTraffic  -0.171155    -0.831775         1.954992      1.950410   \n",
      "DDoS            5.432114     0.625164         9.725309      1.174789   \n",
      "DoS             1.667833     0.827955         9.039214      0.646418   \n",
      "MITM            1.012933    -1.012338         2.099919     -0.068855   \n",
      "Mirai           2.541550     0.591752         9.523045      0.451541   \n",
      "Recon           0.314187     0.077418         1.378529      1.145082   \n",
      "\n",
      "               src_rate    dst_rate  fin_packets  urg_packets  rst_packets  \\\n",
      "BenignTraffic  1.950410    0.000000    16.797437    -0.764106    -1.209842   \n",
      "DDoS           1.174789  731.443299     2.294876     5.758011     8.094977   \n",
      "DoS            0.646418    0.000000     7.331285    13.371337     9.168770   \n",
      "MITM          -0.068855    0.000000    11.515684     0.104884    -0.581471   \n",
      "Mirai          0.451541    0.000000    45.440490    15.499330    12.434691   \n",
      "Recon          1.145082    0.000000     0.939046     0.380289     0.269942   \n",
      "\n",
      "               max_value  value_covariance  \n",
      "BenignTraffic  -0.223367         -1.082881  \n",
      "DDoS            4.612487          3.362645  \n",
      "DoS             3.110075          2.252764  \n",
      "MITM           -0.613685         -1.337782  \n",
      "Mirai           5.614571          0.027221  \n",
      "Recon           0.764373         -0.178258  \n",
      "\n",
      "Skewness after box-cox:\n",
      "                flow_time  header_size  packet_duration  overall_rate  \\\n",
      "BenignTraffic  -4.919068    -1.380333       -35.239004     -0.267039   \n",
      "DDoS            2.250416    -0.000292         8.869358      0.363330   \n",
      "DoS             0.755045     0.740413         7.489166      0.218099   \n",
      "MITM           -3.265133    -1.461756         0.413809     -1.457879   \n",
      "Mirai           0.740512     0.484894         7.435674     -0.277025   \n",
      "Recon          -0.879321    -0.226586       -18.521263     -0.510817   \n",
      "\n",
      "               src_rate  dst_rate  fin_packets  urg_packets  rst_packets  \\\n",
      "BenignTraffic -0.267039       0.0     7.420182    -9.699234   -12.032921   \n",
      "DDoS           0.363330       0.0     2.083882     2.175855     1.970489   \n",
      "DoS            0.218099       0.0     3.708472     5.159432     3.102063   \n",
      "MITM          -1.457879       0.0     7.132164    -1.631426    -2.188905   \n",
      "Mirai         -0.277025       0.0    13.612234     5.421915     4.625474   \n",
      "Recon         -0.510817       0.0     0.574828    -0.790860    -2.550183   \n",
      "\n",
      "               max_value  value_covariance  \n",
      "BenignTraffic  -2.931983         -4.660318  \n",
      "DDoS            0.928908          1.838333  \n",
      "DoS             1.358222          0.981386  \n",
      "MITM           -2.385156         -2.425017  \n",
      "Mirai         -38.560156         -0.139825  \n",
      "Recon          -0.847397         -1.636672  \n",
      "\n",
      "Skewness after yeo-johnson:\n",
      "                flow_time  header_size  packet_duration  overall_rate  \\\n",
      "BenignTraffic  -4.919068    -1.380333       -35.239002     -0.267039   \n",
      "DDoS            2.250416    -0.000292         8.869358      0.363330   \n",
      "DoS             0.755045     0.740413         7.489166      0.218099   \n",
      "MITM           -3.265133    -1.461756         0.413809     -1.457879   \n",
      "Mirai           0.740512     0.484894         7.435674     -0.277025   \n",
      "Recon          -0.879321    -0.226586       -18.521262     -0.510817   \n",
      "\n",
      "               src_rate  dst_rate  fin_packets  urg_packets  rst_packets  \\\n",
      "BenignTraffic -0.267039       0.0     7.420182    -9.699234   -12.032921   \n",
      "DDoS           0.363330       0.0     2.083882     2.175855     1.970489   \n",
      "DoS            0.218099       0.0     3.708472     5.159432     3.102063   \n",
      "MITM          -1.457879       0.0     7.132164    -1.631426    -2.188905   \n",
      "Mirai         -0.277025       0.0    13.612234     5.421915     4.625474   \n",
      "Recon         -0.510817       0.0     0.574828    -0.790860    -2.550183   \n",
      "\n",
      "               max_value  value_covariance  \n",
      "BenignTraffic  -2.936781         -4.660318  \n",
      "DDoS            0.951790          1.838333  \n",
      "DoS             1.365160          0.981386  \n",
      "MITM           -2.386536         -2.425017  \n",
      "Mirai         -38.801133         -0.139825  \n",
      "Recon          -0.847174         -1.636672  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "\n",
    "def fix_skewness(data, numeric_cols, method='log1p'):\n",
    "    \"\"\"\n",
    "    Apply a skewness-fixing transformation to specified numeric columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame\n",
    "    - numeric_cols: list of column names to transform\n",
    "    - method: one of 'log1p', 'box-cox', 'yeo-johnson'\n",
    "\n",
    "    Returns:\n",
    "    - data_transformed: DataFrame with transformed columns\n",
    "    \"\"\"\n",
    "    data_transformed = data.copy()\n",
    "\n",
    "    if method == 'log1p':\n",
    "        data_transformed[numeric_cols] = np.log1p(data_transformed[numeric_cols])\n",
    "\n",
    "    elif method in ['box-cox', 'yeo-johnson']:\n",
    "        # Initialize PowerTransformer\n",
    "        pt = PowerTransformer(method='box-cox' if method == 'box-cox' else 'yeo-johnson', standardize=False)\n",
    "\n",
    "        # For box-cox, ensure all values are positive by shifting if necessary\n",
    "        if method == 'box-cox':\n",
    "            for col in numeric_cols:\n",
    "                min_val = data_transformed[col].min()\n",
    "                if min_val <= 0:\n",
    "                    data_transformed[col] = data_transformed[col] + (1 - min_val)\n",
    "\n",
    "        # Fit & transform\n",
    "        data_transformed[numeric_cols] = pt.fit_transform(data_transformed[numeric_cols])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "    return data_transformed\n",
    "\n",
    "\n",
    "def compute_skewness_by_class(data, numeric_cols, label_col='label'):\n",
    "    \"\"\"\n",
    "    Compute skewness of numeric columns for each class in label_col.\n",
    "\n",
    "    Returns a DataFrame indexed by class labels, columns are numeric_cols.\n",
    "    \"\"\"\n",
    "    skew_dict = {}\n",
    "    for cls, group in data.groupby(label_col):\n",
    "        skew_dict[cls] = group[numeric_cols].skew()\n",
    "    return pd.DataFrame(skew_dict).T\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load your dataset (modify the path as needed)\n",
    "    # data = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "    # ---- Improved detection of true numeric columns ----\n",
    "    # All numeric dtype columns\n",
    "    all_numeric = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    # Exclude binary columns\n",
    "    binary_cols = [col for col in all_numeric if data[col].nunique() == 2]\n",
    "    # Exclude object/category dtype columns\n",
    "    categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    # Exclude low-cardinality numeric columns (likely categorical encoded as numbers)\n",
    "    low_cardinality = [col for col in all_numeric if data[col].nunique() < 10]\n",
    "\n",
    "    # Combine excludes (and always exclude label)\n",
    "    exclude = set(binary_cols + categorical_cols + low_cardinality + ['label'])\n",
    "    numeric_cols = [col for col in all_numeric if col not in exclude]\n",
    "\n",
    "    print(\"Numeric columns to transform:\", numeric_cols)\n",
    "\n",
    "    # Compute skewness before transformation\n",
    "    skew_before = compute_skewness_by_class(data, numeric_cols, label_col='label')\n",
    "    print(\"Skewness before transformations:\\n\", skew_before)\n",
    "\n",
    "    # Apply each method and compute skewness after\n",
    "    for method in ['log1p', 'box-cox', 'yeo-johnson']:\n",
    "        data_trans = fix_skewness(data, numeric_cols, method=method)\n",
    "        skew_after = compute_skewness_by_class(data_trans, numeric_cols, label_col='label')\n",
    "        print(f\"\\nSkewness after {method}:\\n\", skew_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512b66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns in dataset: ['flow_time', 'header_size', 'packet_duration', 'overall_rate', 'src_rate', 'dst_rate', 'fin_packets', 'urg_packets', 'rst_packets', 'max_value', 'value_covariance', 'fin_flags', 'syn_flags', 'rst_flags', 'psh_flags', 'ack_flags', 'protocol_http', 'protocol_https', 'protocol_tcp', 'protocol_udp', 'protocol_icmp', 'label']\n",
      "\n",
      "Binary columns:      ['fin_flags', 'syn_flags', 'rst_flags', 'psh_flags', 'ack_flags', 'protocol_http', 'protocol_https', 'protocol_tcp', 'protocol_udp', 'protocol_icmp']\n",
      "Numeric columns:     ['flow_time', 'header_size', 'packet_duration', 'overall_rate', 'src_rate', 'dst_rate', 'fin_packets', 'urg_packets', 'rst_packets', 'max_value', 'value_covariance']\n",
      "Categorical columns: ['label']\n",
      "\n",
      "Verification:\n",
      "[✓] All columns match exactly.\n",
      "[✓] Binary columns match exactly.\n",
      "[✓] Numeric columns match exactly.\n",
      "[✓] Categorical columns match exactly.\n"
     ]
    }
   ],
   "source": [
    "def separate_columns(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Separates the columns of data into binary, numeric (non-binary), and categorical lists.\n",
    "\n",
    "    Returns:\n",
    "        binary_cols: Columns containing exactly two values {0,1}.\n",
    "        numeric_cols: All other numeric columns.\n",
    "        categorical_cols: Columns of object or category dtype.\n",
    "    \"\"\"\n",
    "    # 1. Identify binary columns: exactly two unique values (0 and 1)\n",
    "    binary_cols = [\n",
    "        col for col in data.columns\n",
    "        if data[col].nunique(dropna=True) == 2\n",
    "           and set(data[col].dropna().unique()) <= {0, 1}\n",
    "    ]\n",
    "\n",
    "    # 2. Identify numeric columns, then exclude binary ones\n",
    "    numeric_cols = [\n",
    "        col for col in data.select_dtypes(include=['number']).columns\n",
    "        if col not in binary_cols\n",
    "    ]\n",
    "\n",
    "    # 3. Identify categorical columns (object or category dtype)\n",
    "    categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    return binary_cols, numeric_cols, categorical_cols\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load your full dataset here:\n",
    "\n",
    "    # 2. Print all columns\n",
    "    print(\"All columns in dataset:\", list(data.columns))\n",
    "\n",
    "    # 3. Separate them\n",
    "    binary_cols, numeric_cols, categorical_cols = separate_columns(data)\n",
    "\n",
    "    # 4. Inspect your lists\n",
    "    print(\"\\nBinary columns:     \", binary_cols)\n",
    "    print(\"Numeric columns:    \", numeric_cols)\n",
    "    print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "    # 5. Define the expected lists\n",
    "    expected_all = [\n",
    "        'flow_time', 'header_size', 'packet_duration', 'overall_rate', \n",
    "        'src_rate', 'dst_rate', 'fin_packets', 'urg_packets', 'rst_packets', \n",
    "        'max_value', 'value_covariance', 'fin_flags', 'syn_flags', 'rst_flags', \n",
    "        'psh_flags', 'ack_flags', 'protocol_http', 'protocol_https', 'protocol_tcp', \n",
    "        'protocol_udp', 'protocol_icmp', 'label'\n",
    "    ]\n",
    "    expected_binary = [\n",
    "        'fin_flags', 'syn_flags', 'rst_flags', 'psh_flags', 'ack_flags',\n",
    "        'protocol_http', 'protocol_https', 'protocol_tcp', 'protocol_udp', 'protocol_icmp'\n",
    "    ]\n",
    "    expected_numeric = [\n",
    "        'flow_time', 'header_size', 'packet_duration', 'overall_rate', \n",
    "        'src_rate', 'dst_rate', 'fin_packets', 'urg_packets', 'rst_packets', \n",
    "        'max_value', 'value_covariance'\n",
    "    ]\n",
    "    expected_categorical = ['label']\n",
    "\n",
    "    # 6. Check for matches and report any differences\n",
    "    def compare_lists(name, actual, expected):\n",
    "        actual_set, expected_set = set(actual), set(expected)\n",
    "        missing = expected_set - actual_set\n",
    "        extra   = actual_set - expected_set\n",
    "        if not missing and not extra:\n",
    "            print(f\"[✓] {name} match exactly.\")\n",
    "        else:\n",
    "            if missing:\n",
    "                print(f\"[✗] {name} missing: {sorted(missing)}\")\n",
    "            if extra:\n",
    "                print(f\"[✗] {name} unexpected: {sorted(extra)}\")\n",
    "\n",
    "    print(\"\\nVerification:\")\n",
    "    compare_lists(\"All columns\", list(data.columns), expected_all)\n",
    "    compare_lists(\"Binary columns\", binary_cols, expected_binary)\n",
    "    compare_lists(\"Numeric columns\", numeric_cols, expected_numeric)\n",
    "    compare_lists(\"Categorical columns\", categorical_cols, expected_categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d0bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- IMBALANCE ANALYSIS SUMMARY ---\n",
      "\n",
      "\n",
      "=== Direct_Removal ===\n",
      "\n",
      "Target Variable: label\n",
      "  Train: 96.44% class 1 (Imbalance Ratio: 27.08)\n",
      "  Test:  96.44% class 1 (Imbalance Ratio: 27.08)\n",
      "\n",
      "Binary Features:\n",
      "\n",
      "  fin_flags:\n",
      "    Train: 92.35% class 0 (Imbalance Ratio: 12.07)\n",
      "    Test:  92.37% class 0 (Imbalance Ratio: 12.11)\n",
      "\n",
      "  syn_flags:\n",
      "    Train: 78.19% class 0 (Imbalance Ratio: 3.58)\n",
      "    Test:  78.37% class 0 (Imbalance Ratio: 3.62)\n",
      "\n",
      "  rst_flags:\n",
      "    Train: 91.90% class 0 (Imbalance Ratio: 11.34)\n",
      "    Test:  91.94% class 0 (Imbalance Ratio: 11.40)\n",
      "\n",
      "  psh_flags:\n",
      "    Train: 91.57% class 0 (Imbalance Ratio: 10.86)\n",
      "    Test:  91.57% class 0 (Imbalance Ratio: 10.86)\n",
      "\n",
      "  ack_flags:\n",
      "    Train: 87.87% class 0 (Imbalance Ratio: 7.25)\n",
      "    Test:  87.86% class 0 (Imbalance Ratio: 7.24)\n",
      "\n",
      "  protocol_http:\n",
      "    Train: 95.21% class 0 (Imbalance Ratio: 19.86)\n",
      "    Test:  95.19% class 0 (Imbalance Ratio: 19.81)\n",
      "\n",
      "  protocol_https:\n",
      "    Train: 94.28% class 0 (Imbalance Ratio: 16.49)\n",
      "    Test:  94.25% class 0 (Imbalance Ratio: 16.40)\n",
      "\n",
      "  protocol_tcp:\n",
      "    Train: 57.17% class 1 (Imbalance Ratio: 1.33)\n",
      "    Test:  57.22% class 1 (Imbalance Ratio: 1.34)\n",
      "\n",
      "  protocol_udp:\n",
      "    Train: 76.48% class 0 (Imbalance Ratio: 3.25)\n",
      "    Test:  76.42% class 0 (Imbalance Ratio: 3.24)\n",
      "\n",
      "  protocol_icmp:\n",
      "    Train: 86.06% class 0 (Imbalance Ratio: 6.17)\n",
      "    Test:  86.03% class 0 (Imbalance Ratio: 6.16)\n",
      "\n",
      "=== Instance_Weighting ===\n",
      "\n",
      "Target Variable: label\n",
      "  Train: 96.90% class 1 (Imbalance Ratio: 31.25)\n",
      "  Test:  96.90% class 1 (Imbalance Ratio: 31.25)\n",
      "\n",
      "Binary Features:\n",
      "\n",
      "  fin_flags:\n",
      "    Train: 91.29% class 0 (Imbalance Ratio: 10.49)\n",
      "    Test:  91.27% class 0 (Imbalance Ratio: 10.46)\n",
      "\n",
      "  syn_flags:\n",
      "    Train: 79.21% class 0 (Imbalance Ratio: 3.81)\n",
      "    Test:  79.01% class 0 (Imbalance Ratio: 3.76)\n",
      "\n",
      "  rst_flags:\n",
      "    Train: 90.89% class 0 (Imbalance Ratio: 9.98)\n",
      "    Test:  90.86% class 0 (Imbalance Ratio: 9.95)\n",
      "\n",
      "  psh_flags:\n",
      "    Train: 91.17% class 0 (Imbalance Ratio: 10.33)\n",
      "    Test:  91.10% class 0 (Imbalance Ratio: 10.24)\n",
      "\n",
      "  ack_flags:\n",
      "    Train: 87.87% class 0 (Imbalance Ratio: 7.24)\n",
      "    Test:  87.79% class 0 (Imbalance Ratio: 7.19)\n",
      "\n",
      "  protocol_http:\n",
      "    Train: 95.23% class 0 (Imbalance Ratio: 19.95)\n",
      "    Test:  95.09% class 0 (Imbalance Ratio: 19.39)\n",
      "\n",
      "  protocol_https:\n",
      "    Train: 94.59% class 0 (Imbalance Ratio: 17.49)\n",
      "    Test:  94.54% class 0 (Imbalance Ratio: 17.31)\n",
      "\n",
      "  protocol_tcp:\n",
      "    Train: 57.38% class 1 (Imbalance Ratio: 1.35)\n",
      "    Test:  57.56% class 1 (Imbalance Ratio: 1.36)\n",
      "\n",
      "  protocol_udp:\n",
      "    Train: 78.84% class 0 (Imbalance Ratio: 3.73)\n",
      "    Test:  78.94% class 0 (Imbalance Ratio: 3.75)\n",
      "\n",
      "  protocol_icmp:\n",
      "    Train: 83.56% class 0 (Imbalance Ratio: 5.08)\n",
      "    Test:  83.62% class 0 (Imbalance Ratio: 5.10)\n",
      "\n",
      "=== Train_Test_Aware ===\n",
      "\n",
      "Target Variable: label\n",
      "  Train: 96.84% class 1 (Imbalance Ratio: 30.63)\n",
      "  Test:  96.81% class 1 (Imbalance Ratio: 30.34)\n",
      "\n",
      "Binary Features:\n",
      "\n",
      "  fin_flags:\n",
      "    Train: 91.45% class 0 (Imbalance Ratio: 10.70)\n",
      "    Test:  91.40% class 0 (Imbalance Ratio: 10.63)\n",
      "\n",
      "  syn_flags:\n",
      "    Train: 79.04% class 0 (Imbalance Ratio: 3.77)\n",
      "    Test:  79.07% class 0 (Imbalance Ratio: 3.78)\n",
      "\n",
      "  rst_flags:\n",
      "    Train: 91.04% class 0 (Imbalance Ratio: 10.16)\n",
      "    Test:  90.97% class 0 (Imbalance Ratio: 10.08)\n",
      "\n",
      "  psh_flags:\n",
      "    Train: 91.19% class 0 (Imbalance Ratio: 10.35)\n",
      "    Test:  91.25% class 0 (Imbalance Ratio: 10.42)\n",
      "\n",
      "  ack_flags:\n",
      "    Train: 87.82% class 0 (Imbalance Ratio: 7.21)\n",
      "    Test:  87.89% class 0 (Imbalance Ratio: 7.26)\n",
      "\n",
      "  protocol_http:\n",
      "    Train: 95.17% class 0 (Imbalance Ratio: 19.68)\n",
      "    Test:  95.21% class 0 (Imbalance Ratio: 19.88)\n",
      "\n",
      "  protocol_https:\n",
      "    Train: 94.54% class 0 (Imbalance Ratio: 17.31)\n",
      "    Test:  94.46% class 0 (Imbalance Ratio: 17.06)\n",
      "\n",
      "  protocol_tcp:\n",
      "    Train: 57.45% class 1 (Imbalance Ratio: 1.35)\n",
      "    Test:  57.55% class 1 (Imbalance Ratio: 1.36)\n",
      "\n",
      "  protocol_udp:\n",
      "    Train: 78.49% class 0 (Imbalance Ratio: 3.65)\n",
      "    Test:  78.51% class 0 (Imbalance Ratio: 3.65)\n",
      "\n",
      "  protocol_icmp:\n",
      "    Train: 83.94% class 0 (Imbalance Ratio: 5.23)\n",
      "    Test:  84.07% class 0 (Imbalance Ratio: 5.28)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the paths to your datasets based on your directory structure\n",
    "base_paths = [\n",
    "    'Data/deduplicated_datasets/Direct_Removal/phase2_Direct_Removal',\n",
    "    'Data/deduplicated_datasets/Instance_Weighting/phase2_Instance_Weighting',\n",
    "    'Data/deduplicated_datasets/Train_Test_Aware/phase2_TrainTestAware'\n",
    "]\n",
    "\n",
    "binary_cols = ['fin_flags', 'syn_flags', 'rst_flags', 'psh_flags', 'ack_flags', \n",
    "               'protocol_http', 'protocol_https', 'protocol_tcp', 'protocol_udp', 'protocol_icmp']\n",
    "\n",
    "# Function to calculate imbalance metrics\n",
    "def calculate_imbalance(data, cols):\n",
    "    results = {}\n",
    "    for col in cols:\n",
    "        if col in data.columns:\n",
    "            # Count of 1s and 0s\n",
    "            value_counts = data[col].value_counts()\n",
    "            count_0 = value_counts.get(0, 0)\n",
    "            count_1 = value_counts.get(1, 0)\n",
    "            total = count_0 + count_1\n",
    "            \n",
    "            # Percentage of 1s and 0s\n",
    "            pct_0 = count_0 / total * 100 if total > 0 else 0\n",
    "            pct_1 = count_1 / total * 100 if total > 0 else 0\n",
    "            \n",
    "            # Imbalance ratio (higher value = more imbalanced)\n",
    "            imbalance_ratio = max(pct_0, pct_1) / min(pct_0, pct_1) if min(pct_0, pct_1) > 0 else float('inf')\n",
    "            \n",
    "            results[col] = {\n",
    "                'count_0': count_0,\n",
    "                'count_1': count_1,\n",
    "                'pct_0': pct_0,\n",
    "                'pct_1': pct_1,\n",
    "                'imbalance_ratio': imbalance_ratio,\n",
    "                'majority': '0' if pct_0 > pct_1 else '1',\n",
    "                'majority_pct': max(pct_0, pct_1)\n",
    "            }\n",
    "    return results\n",
    "\n",
    "# Store results for each dataset\n",
    "all_results = {}\n",
    "\n",
    "for base_path in base_paths:\n",
    "    experiment_name = base_path.split('/')[2]\n",
    "    all_results[experiment_name] = {}\n",
    "    \n",
    "    # Load training and test data\n",
    "    try:\n",
    "        X_train = pd.read_csv(f'{base_path}_X_train.csv')\n",
    "        X_test = pd.read_csv(f'{base_path}_X_test.csv')\n",
    "        y_train = pd.read_csv(f'{base_path}_y_train.csv')\n",
    "        y_test = pd.read_csv(f'{base_path}_y_test.csv')\n",
    "        \n",
    "        # Calculate imbalance for features\n",
    "        train_imbalance = calculate_imbalance(X_train, binary_cols)\n",
    "        test_imbalance = calculate_imbalance(X_test, binary_cols)\n",
    "        \n",
    "        # Calculate imbalance for target variable\n",
    "        y_train_imbalance = calculate_imbalance(y_train, y_train.columns)\n",
    "        y_test_imbalance = calculate_imbalance(y_test, y_test.columns)\n",
    "        \n",
    "        all_results[experiment_name] = {\n",
    "            'X_train': train_imbalance,\n",
    "            'X_test': test_imbalance,\n",
    "            'y_train': y_train_imbalance,\n",
    "            'y_test': y_test_imbalance\n",
    "        }\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Could not find one or more files for {experiment_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Function to print results in a readable format\n",
    "def print_imbalance_summary(results):\n",
    "    print(\"\\n--- IMBALANCE ANALYSIS SUMMARY ---\\n\")\n",
    "    \n",
    "    for experiment, datasets in results.items():\n",
    "        print(f\"\\n=== {experiment} ===\")\n",
    "        \n",
    "        # First, check target variable imbalance\n",
    "        if 'y_train' in datasets and 'y_test' in datasets:\n",
    "            for target_col, target_stats in datasets['y_train'].items():\n",
    "                train_majority = target_stats['majority']\n",
    "                train_majority_pct = target_stats['majority_pct']\n",
    "                \n",
    "                test_stats = datasets['y_test'].get(target_col, {})\n",
    "                test_majority = test_stats.get('majority', 'N/A')\n",
    "                test_majority_pct = test_stats.get('majority_pct', 0)\n",
    "                \n",
    "                print(f\"\\nTarget Variable: {target_col}\")\n",
    "                print(f\"  Train: {train_majority_pct:.2f}% class {train_majority} (Imbalance Ratio: {target_stats['imbalance_ratio']:.2f})\")\n",
    "                print(f\"  Test:  {test_majority_pct:.2f}% class {test_majority} (Imbalance Ratio: {test_stats.get('imbalance_ratio', 'N/A'):.2f})\")\n",
    "        \n",
    "        # Then, feature imbalance\n",
    "        print(\"\\nBinary Features:\")\n",
    "        for feature in binary_cols:\n",
    "            if feature in datasets.get('X_train', {}) and feature in datasets.get('X_test', {}):\n",
    "                train_stats = datasets['X_train'][feature]\n",
    "                test_stats = datasets['X_test'][feature]\n",
    "                \n",
    "                print(f\"\\n  {feature}:\")\n",
    "                print(f\"    Train: {train_stats['majority_pct']:.2f}% class {train_stats['majority']} (Imbalance Ratio: {train_stats['imbalance_ratio']:.2f})\")\n",
    "                print(f\"    Test:  {test_stats['majority_pct']:.2f}% class {test_stats['majority']} (Imbalance Ratio: {test_stats['imbalance_ratio']:.2f})\")\n",
    "                \n",
    "                # Calculate distribution shift between train and test\n",
    "                train_pct_1 = train_stats['pct_1']\n",
    "                test_pct_1 = test_stats['pct_1']\n",
    "                dist_shift = abs(train_pct_1 - test_pct_1)\n",
    "                \n",
    "                if dist_shift > 5:  # More than 5% difference\n",
    "                    print(f\"    ⚠️ Distribution shift: {dist_shift:.2f}% difference between train and test\")\n",
    "\n",
    "# Print the results\n",
    "print_imbalance_summary(all_results)\n",
    "\n",
    "# Create output directory for visualizations if it doesn't exist\n",
    "os.makedirs('imbalance_analysis', exist_ok=True)\n",
    "\n",
    "# Create visualizations\n",
    "def create_imbalance_visualizations(results):\n",
    "    for experiment, datasets in results.items():\n",
    "        # Set up the figure\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Create data for plotting\n",
    "        features = [col for col in binary_cols if col in datasets.get('X_train', {})]\n",
    "        train_imbalance = [datasets['X_train'][col]['imbalance_ratio'] for col in features]\n",
    "        test_imbalance = [datasets['X_test'][col]['imbalance_ratio'] for col in features]\n",
    "        \n",
    "        # For features with very high imbalance, cap at 100 for visualization\n",
    "        train_imbalance = [min(x, 100) for x in train_imbalance]\n",
    "        test_imbalance = [min(x, 100) for x in test_imbalance]\n",
    "        \n",
    "        # Create bar chart\n",
    "        x = np.arange(len(features))\n",
    "        width = 0.35\n",
    "        \n",
    "        plt.bar(x - width/2, train_imbalance, width, label='Train')\n",
    "        plt.bar(x + width/2, test_imbalance, width, label='Test')\n",
    "        \n",
    "        plt.xlabel('Binary Features')\n",
    "        plt.ylabel('Imbalance Ratio (capped at 100)')\n",
    "        plt.title(f'Feature Imbalance - {experiment}')\n",
    "        plt.xticks(x, features, rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(f'imbalance_analysis/{experiment}_imbalance.png')\n",
    "        plt.close()\n",
    "\n",
    "# Create visualizations\n",
    "create_imbalance_visualizations(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cee7c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MULTI-CLASS TARGET LABEL DISTRIBUTION ===\n",
      "\n",
      "\n",
      "Direct_Removal:\n",
      "  Unique classes: [0, 1, 2, 3, 4, 5]\n",
      "  Class distribution:\n",
      "    - Class 0: 17,588 samples (2.62%)\n",
      "    - Class 1: 476,204 samples (70.90%)\n",
      "    - Class 2: 126,690 samples (18.86%)\n",
      "    - Class 3: 5,050 samples (0.75%)\n",
      "    - Class 4: 41,018 samples (6.11%)\n",
      "    - Class 5: 5,146 samples (0.77%)\n",
      "  Most common: Class 1 (70.90%)\n",
      "  Least common: Class 3 (0.75%)\n",
      "  Imbalance ratio: 94.30\n",
      "\n",
      "Instance_Weighting:\n",
      "  Unique classes: [0, 1, 2, 3, 4, 5]\n",
      "  Class distribution:\n",
      "    - Class 0: 17,590 samples (2.34%)\n",
      "    - Class 1: 549,621 samples (73.20%)\n",
      "    - Class 2: 130,742 samples (17.41%)\n",
      "    - Class 3: 5,051 samples (0.67%)\n",
      "    - Class 4: 42,716 samples (5.69%)\n",
      "    - Class 5: 5,146 samples (0.69%)\n",
      "  Most common: Class 1 (73.20%)\n",
      "  Least common: Class 3 (0.67%)\n",
      "  Imbalance ratio: 108.81\n",
      "\n",
      "Train_Test_Aware:\n",
      "  Unique classes: [0, 1, 2, 3, 4, 5]\n",
      "  Class distribution:\n",
      "    - Class 0: 17,558 samples (2.38%)\n",
      "    - Class 1: 537,805 samples (72.91%)\n",
      "    - Class 2: 130,059 samples (17.63%)\n",
      "    - Class 3: 5,091 samples (0.69%)\n",
      "    - Class 4: 41,898 samples (5.68%)\n",
      "    - Class 5: 5,169 samples (0.70%)\n",
      "  Most common: Class 1 (72.91%)\n",
      "  Least common: Class 3 (0.69%)\n",
      "  Imbalance ratio: 105.64\n",
      "\n",
      "Visualization saved to 'imbalance_analysis/multiclass_distribution.png'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths to your target datasets\n",
    "target_paths = [\n",
    "    'Data/deduplicated_datasets/Direct_Removal/phase2_Direct_Removal_y_train.csv',\n",
    "    'Data/deduplicated_datasets/Instance_Weighting/phase2_Instance_Weighting_y_train.csv', \n",
    "    'Data/deduplicated_datasets/Train_Test_Aware/phase2_TrainTestAware_y_train.csv'\n",
    "]\n",
    "\n",
    "# Names of the techniques for reporting\n",
    "technique_names = ['Direct_Removal', 'Instance_Weighting', 'Train_Test_Aware']\n",
    "\n",
    "# Function to analyze multi-class distribution\n",
    "def analyze_multiclass_distribution(file_path):\n",
    "    # Read the target data\n",
    "    y_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Assuming the column is named 'label'\n",
    "    target_col = 'label' if 'label' in y_data.columns else y_data.columns[0]\n",
    "    \n",
    "    # Count each unique value\n",
    "    value_counts = y_data[target_col].value_counts().sort_index()\n",
    "    total = len(y_data)\n",
    "    \n",
    "    # Calculate percentages for each class\n",
    "    percentages = (value_counts / total * 100).to_dict()\n",
    "    \n",
    "    # Get the counts as a dictionary\n",
    "    counts = value_counts.to_dict()\n",
    "    \n",
    "    # Find the most common and least common classes\n",
    "    most_common_class = value_counts.idxmax()\n",
    "    least_common_class = value_counts.idxmin()\n",
    "    \n",
    "    # Calculate imbalance ratio (most common to least common)\n",
    "    imbalance_ratio = value_counts.max() / value_counts.min()\n",
    "    \n",
    "    return {\n",
    "        'counts': counts,\n",
    "        'percentages': percentages,\n",
    "        'most_common_class': most_common_class,\n",
    "        'least_common_class': least_common_class,\n",
    "        'imbalance_ratio': imbalance_ratio,\n",
    "        'unique_classes': sorted(value_counts.index.tolist())\n",
    "    }\n",
    "\n",
    "# Print header\n",
    "print(\"\\n=== MULTI-CLASS TARGET LABEL DISTRIBUTION ===\\n\")\n",
    "\n",
    "# Analyze each technique\n",
    "for i, path in enumerate(target_paths):\n",
    "    try:\n",
    "        print(f\"\\n{technique_names[i]}:\")\n",
    "        metrics = analyze_multiclass_distribution(path)\n",
    "        \n",
    "        print(f\"  Unique classes: {metrics['unique_classes']}\")\n",
    "        print(f\"  Class distribution:\")\n",
    "        \n",
    "        for cls, pct in metrics['percentages'].items():\n",
    "            count = metrics['counts'][cls]\n",
    "            print(f\"    - Class {cls}: {count:,} samples ({pct:.2f}%)\")\n",
    "        \n",
    "        print(f\"  Most common: Class {metrics['most_common_class']} ({metrics['percentages'][metrics['most_common_class']]:.2f}%)\")\n",
    "        print(f\"  Least common: Class {metrics['least_common_class']} ({metrics['percentages'][metrics['least_common_class']]:.2f}%)\")\n",
    "        print(f\"  Imbalance ratio: {metrics['imbalance_ratio']:.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{technique_names[i]}: Error - {e}\")\n",
    "\n",
    "# Create output directory for visualizations if it doesn't exist\n",
    "import os\n",
    "os.makedirs('imbalance_analysis', exist_ok=True)\n",
    "\n",
    "# Visualize the multi-class distribution for each technique\n",
    "def create_multiclass_visualizations(target_paths, technique_names):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, (path, name) in enumerate(zip(target_paths, technique_names)):\n",
    "        plt.subplot(len(target_paths), 1, i+1)\n",
    "        \n",
    "        # Read data\n",
    "        y_data = pd.read_csv(path)\n",
    "        target_col = 'label' if 'label' in y_data.columns else y_data.columns[0]\n",
    "        \n",
    "        # Count values\n",
    "        value_counts = y_data[target_col].value_counts().sort_index()\n",
    "        \n",
    "        # Create bar plot\n",
    "        bars = plt.bar(value_counts.index.astype(str), value_counts.values, color='steelblue')\n",
    "        \n",
    "        # Add count labels on top of the bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                     f'{height:,}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.title(f'Class Distribution - {name}')\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('imbalance_analysis/multiclass_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "# Create visualizations\n",
    "create_multiclass_visualizations(target_paths, technique_names)\n",
    "print(\"\\nVisualization saved to 'imbalance_analysis/multiclass_distribution.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677a041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully read 'C:\\Machine Learning\\Phase 2\\Data\\phase2_students_before_cleaning.csv' with encoding: utf-8\n",
      "\n",
      "Label encoding mapping:\n",
      "  'BenignTraffic' → 0\n",
      "  'DDoS' → 1\n",
      "  'DoS' → 2\n",
      "  'MITM' → 3\n",
      "  'Mirai' → 4\n",
      "  'Recon' → 5\n",
      "\n",
      "=== IMBALANCE ANALYSIS ON ENCODED LABELS ===\n",
      "Unique encoded classes: [0, 1, 2, 3, 4, 5]\n",
      "Class distribution:\n",
      "  - Class 0: 21,987 samples (2.34%)\n",
      "  - Class 1: 687,027 samples (73.2%)\n",
      "  - Class 2: 163,428 samples (17.41%)\n",
      "  - Class 3: 6,313 samples (0.67%)\n",
      "  - Class 4: 53,395 samples (5.69%)\n",
      "  - Class 5: 6,433 samples (0.69%)\n",
      "\n",
      "Most common: Class 1 (73.2%)\n",
      "Least common: Class 3 (0.67%)\n",
      "Imbalance ratio: 108.83\n",
      "\n",
      "Visualization saved to 'imbalance_analysis/sample_submission_distribution.png'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Path to your original dataset\n",
    "file_path = r'C:\\Machine Learning\\Phase 2\\Data\\phase2_students_before_cleaning.csv'\n",
    "\n",
    "# Try a list of encodings until one works\n",
    "encodings_to_try = ['utf-8', 'latin1', 'ISO-8859-1', 'cp1252']\n",
    "for enc in encodings_to_try:\n",
    "    try:\n",
    "        data = pd.read_csv(file_path, encoding=enc)\n",
    "        print(f\"✅ Successfully read '{file_path}' with encoding: {enc}\")\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"⚠️  Failed to decode with {enc}, trying next…\")\n",
    "else:\n",
    "    raise UnicodeDecodeError(f\"Could not read '{file_path}' with any of {encodings_to_try}\")\n",
    "\n",
    "# Ensure we have the 'label' column\n",
    "if 'label' not in data.columns:\n",
    "    raise KeyError(f\"'label' column not found in {file_path}; found columns: {data.columns.tolist()}\")\n",
    "\n",
    "# Label-encode the 'label' column\n",
    "le = LabelEncoder()\n",
    "data['label_encoded'] = le.fit_transform(data['label'])\n",
    "\n",
    "# Print the mapping\n",
    "print(\"\\nLabel encoding mapping:\")\n",
    "for orig, code in zip(le.classes_, le.transform(le.classes_)):\n",
    "    print(f\"  {orig!r} → {code}\")\n",
    "\n",
    "# Compute class counts & percentages\n",
    "counts = data['label_encoded'].value_counts().sort_index()\n",
    "total = counts.sum()\n",
    "percentages = (counts / total * 100).round(2)\n",
    "\n",
    "most_common = counts.idxmax()\n",
    "least_common = counts.idxmin()\n",
    "imbalance_ratio = counts.max() / counts.min()\n",
    "\n",
    "# Display imbalance metrics\n",
    "print(\"\\n=== IMBALANCE ANALYSIS ON ENCODED LABELS ===\")\n",
    "print(f\"Unique encoded classes: {list(counts.index)}\")\n",
    "print(\"Class distribution:\")\n",
    "for cls in counts.index:\n",
    "    print(f\"  - Class {cls}: {counts[cls]:,} samples ({percentages[cls]}%)\")\n",
    "print(f\"\\nMost common: Class {most_common} ({percentages[most_common]}%)\")\n",
    "print(f\"Least common: Class {least_common} ({percentages[least_common]}%)\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "\n",
    "# Plotting\n",
    "os.makedirs('imbalance_analysis', exist_ok=True)\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(counts.index.astype(str), counts.values, color='steelblue')\n",
    "for bar in bars:\n",
    "    h = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, h + total*0.005,\n",
    "             f'{int(h):,}', ha='center', va='bottom')\n",
    "plt.title('Encoded Class Distribution – sample_submission.csv')\n",
    "plt.xlabel('Encoded Class')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = 'imbalance_analysis/sample_submission_distribution.png'\n",
    "plt.savefig(out_path)\n",
    "plt.close()\n",
    "print(f\"\\nVisualization saved to '{out_path}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
